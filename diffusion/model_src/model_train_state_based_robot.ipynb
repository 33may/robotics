{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-16T22:48:26.695006Z",
     "start_time": "2025-06-16T22:48:26.644980Z"
    }
   },
   "source": "import numpy as np",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T22:48:26.735708Z",
     "start_time": "2025-06-16T22:48:26.697816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "451e1679820bc4a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T22:48:28.082615Z",
     "start_time": "2025-06-16T22:48:27.151162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from robotics.model_src.dataset import RobosuiteImageActionDataset\n",
    "\n",
    "data_path = \"../robomimic/datasets/tool_hang/ph/image_griper.hdf5\"\n",
    "\n",
    "camera_type = None\n",
    "\n",
    "pred_horizon = 8\n",
    "obs_horizon = 4\n",
    "\n",
    "ds = RobosuiteImageActionDataset(data_path, camera_type, obs_horizon = obs_horizon, prediction_horizon = pred_horizon)"
   ],
   "id": "15b0b932e8ea03a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 4709.79it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 42532.11it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T22:48:28.306902Z",
     "start_time": "2025-06-16T22:48:28.085288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "val_ratio = 0.1\n",
    "n_total   = len(ds)\n",
    "n_val     = int(n_total * val_ratio)\n",
    "n_train   = n_total - n_val\n",
    "\n",
    "generator = torch.Generator().manual_seed(33)\n",
    "train_set, val_set = torch.utils.data.random_split(\n",
    "        ds, [n_train, n_val], generator=generator)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=512, shuffle=True,\n",
    "    num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set, batch_size=512, shuffle=False,\n",
    "    num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "\n",
    "# visualize data in batch\n",
    "batch = next(iter(train_loader))\n",
    "print(\"batch['image'].shape:\", batch['img_obs'].shape)\n",
    "print(\"batch['act_obs'].shape:\", batch['act_obs'].shape)\n",
    "print(\"batch['act_pred'].shape\", batch['act_pred'].shape)"
   ],
   "id": "3620e228ccd45a0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch['image'].shape: torch.Size([512, 5, 58])\n",
      "batch['act_obs'].shape: torch.Size([512, 5, 7])\n",
      "batch['act_pred'].shape torch.Size([512, 8, 7])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T22:48:59.985679Z",
     "start_time": "2025-06-16T22:48:57.535583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from robotics.model_src.diffusion_model import ConditionalUnet1D, ConditionalUnet1DTransformer\n",
    "from robotics.model_src.visual_encoder import CNNVisualEncoder\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "obs_feature_dim = ds.obs_shape[0]\n",
    "\n",
    "action_observation_dim = 7\n",
    "\n",
    "# obs_dim = obs_feature_dim + action_observation_dim\n",
    "\n",
    "obs_dim = obs_feature_dim\n",
    "\n",
    "action_dim = 7\n",
    "\n",
    "noise_prediction_net = ConditionalUnet1DTransformer(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim * obs_horizon,\n",
    ").to(device)"
   ],
   "id": "e47fb6462d5a49a1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/may33/miniconda3/envs/diffusion/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/home/may33/miniconda3/envs/diffusion/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/may33/miniconda3/envs/diffusion/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 9.124929e+07\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T22:49:01.632861Z",
     "start_time": "2025-06-16T22:49:01.612866Z"
    }
   },
   "cell_type": "code",
   "source": "model_size = 9.163636e+07",
   "id": "e6e54351561ba0ae",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T22:49:06.048245Z",
     "start_time": "2025-06-16T22:49:05.912602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "\n",
    "num_diffusion_iters = 100\n",
    "\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    clip_sample=True,\n",
    "    prediction_type='epsilon'\n",
    ")"
   ],
   "id": "768b64e659a6c9d7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T00:50:35.964001Z",
     "start_time": "2025-06-17T00:04:20.842643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from diffusers import EMAModel, get_scheduler\n",
    "\n",
    "def forward_loss(nbatch):\n",
    "    nobs  = nbatch['img_obs'][:, :obs_horizon].to(device)\n",
    "    a_obs = nbatch['act_obs'][:, :obs_horizon].to(device)\n",
    "    a_gt  = nbatch['act_pred'].to(device)\n",
    "    B = a_obs.size(0)\n",
    "\n",
    "\n",
    "    obs_features = nobs\n",
    "    # obs_features = torch.cat([nobs, a_obs], dim=-1)\n",
    "    obs_cond = obs_features.flatten(start_dim=1)\n",
    "\n",
    "    noise = torch.randn_like(a_gt)\n",
    "    timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps,\n",
    "                               (B,), device=device).long()\n",
    "    noisy_a = noise_scheduler.add_noise(a_gt, noise, timesteps)\n",
    "    noise_pred = noise_prediction_net(noisy_a, timesteps, global_cond=obs_cond)\n",
    "    return nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "# EMA params\n",
    "all_params = list(noise_prediction_net.parameters())\n",
    "ema = EMAModel(parameters=all_params, power=0.75)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=all_params,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-6\n",
    ")\n",
    "\n",
    "# LR scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(train_loader) * num_epochs\n",
    ")\n",
    "\n",
    "\n",
    "# train loop\n",
    "train_hist, val_hist = [], []\n",
    "for epoch_idx in range(num_epochs):\n",
    "    epoch_loss_sum = 0.0\n",
    "\n",
    "    for nbatch in train_loader:\n",
    "        # prepare data\n",
    "        nobs = nbatch['img_obs'][:, :obs_horizon].to(device)  # (B, H, state_len)\n",
    "        action_obs = nbatch['act_obs'][:, :obs_horizon].to(device)  # (B, H, 7)\n",
    "        action_pred = nbatch['act_pred'].to(device)  # (B, P, 7)\n",
    "        B = action_obs.size(0)\n",
    "\n",
    "        # obs_features = torch.cat([nobs, action_obs], dim=-1)\n",
    "        obs_features = nobs\n",
    "\n",
    "        obs_cond = obs_features.flatten(start_dim=1)  # (B, H*obs_dim)\n",
    "\n",
    "        noise = torch.randn_like(action_pred)\n",
    "        timesteps = torch.randint(\n",
    "            0, noise_scheduler.config.num_train_timesteps,\n",
    "            (B,), device=device).long()\n",
    "\n",
    "        noisy_actions = noise_scheduler.add_noise(action_pred, noise, timesteps)\n",
    "        noise_pred = noise_prediction_net(noisy_actions, timesteps, global_cond=obs_cond)\n",
    "\n",
    "        loss = nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        lr_scheduler.step()\n",
    "        ema.step(all_params)\n",
    "\n",
    "        epoch_loss_sum += loss.item()\n",
    "\n",
    "        avg_train = epoch_loss_sum / len(train_loader)\n",
    "        train_hist.append(avg_train)\n",
    "\n",
    "    # validation\n",
    "    noise_prediction_net.eval()\n",
    "    val_sum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            val_sum += forward_loss(batch).item()\n",
    "    avg_val = val_sum / len(val_loader)\n",
    "    val_hist.append(avg_val)\n",
    "\n",
    "    print(f\"Epoch {epoch_idx+1:03d}/{num_epochs} | \"\n",
    "          f\"train {avg_train:.6f} | val {avg_val:.6f}\")\n",
    "\n",
    "# copy EMA weights for inference\n",
    "ema.copy_to(all_params)"
   ],
   "id": "5d0eb20edab574b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/200 | train 0.021189 | val 0.027548\n",
      "Epoch 002/200 | train 0.025219 | val 0.031022\n",
      "Epoch 003/200 | train 0.027860 | val 0.032817\n",
      "Epoch 004/200 | train 0.028724 | val 0.032325\n",
      "Epoch 005/200 | train 0.028734 | val 0.033084\n",
      "Epoch 006/200 | train 0.029250 | val 0.030723\n",
      "Epoch 007/200 | train 0.028803 | val 0.031742\n",
      "Epoch 008/200 | train 0.029191 | val 0.031183\n",
      "Epoch 009/200 | train 0.028572 | val 0.033228\n",
      "Epoch 010/200 | train 0.029057 | val 0.031237\n",
      "Epoch 011/200 | train 0.029011 | val 0.031274\n",
      "Epoch 012/200 | train 0.028611 | val 0.032112\n",
      "Epoch 013/200 | train 0.028974 | val 0.032849\n",
      "Epoch 014/200 | train 0.028932 | val 0.031709\n",
      "Epoch 015/200 | train 0.029081 | val 0.032740\n",
      "Epoch 016/200 | train 0.029192 | val 0.032069\n",
      "Epoch 017/200 | train 0.028338 | val 0.031463\n",
      "Epoch 018/200 | train 0.029103 | val 0.030677\n",
      "Epoch 019/200 | train 0.028265 | val 0.031312\n",
      "Epoch 020/200 | train 0.028440 | val 0.031985\n",
      "Epoch 021/200 | train 0.028636 | val 0.031185\n",
      "Epoch 022/200 | train 0.027919 | val 0.029555\n",
      "Epoch 023/200 | train 0.028095 | val 0.031786\n",
      "Epoch 024/200 | train 0.028412 | val 0.029761\n",
      "Epoch 025/200 | train 0.028070 | val 0.030383\n",
      "Epoch 026/200 | train 0.027781 | val 0.030492\n",
      "Epoch 027/200 | train 0.028206 | val 0.031488\n",
      "Epoch 028/200 | train 0.027319 | val 0.031067\n",
      "Epoch 029/200 | train 0.027748 | val 0.030463\n",
      "Epoch 030/200 | train 0.027720 | val 0.029473\n",
      "Epoch 031/200 | train 0.027387 | val 0.030091\n",
      "Epoch 032/200 | train 0.027328 | val 0.030361\n",
      "Epoch 033/200 | train 0.027030 | val 0.029449\n",
      "Epoch 034/200 | train 0.027118 | val 0.029071\n",
      "Epoch 035/200 | train 0.026946 | val 0.029256\n",
      "Epoch 036/200 | train 0.026766 | val 0.029895\n",
      "Epoch 037/200 | train 0.026503 | val 0.029335\n",
      "Epoch 038/200 | train 0.026616 | val 0.030690\n",
      "Epoch 039/200 | train 0.026438 | val 0.029216\n",
      "Epoch 040/200 | train 0.026443 | val 0.029182\n",
      "Epoch 041/200 | train 0.026125 | val 0.030050\n",
      "Epoch 042/200 | train 0.026147 | val 0.029137\n",
      "Epoch 043/200 | train 0.025910 | val 0.029669\n",
      "Epoch 044/200 | train 0.025524 | val 0.029647\n",
      "Epoch 045/200 | train 0.026167 | val 0.029683\n",
      "Epoch 046/200 | train 0.026000 | val 0.028094\n",
      "Epoch 047/200 | train 0.025582 | val 0.029900\n",
      "Epoch 048/200 | train 0.025622 | val 0.028409\n",
      "Epoch 049/200 | train 0.025019 | val 0.028437\n",
      "Epoch 050/200 | train 0.025030 | val 0.027988\n",
      "Epoch 051/200 | train 0.025311 | val 0.029151\n",
      "Epoch 052/200 | train 0.025578 | val 0.028622\n",
      "Epoch 053/200 | train 0.024880 | val 0.027673\n",
      "Epoch 054/200 | train 0.024610 | val 0.029567\n",
      "Epoch 055/200 | train 0.024843 | val 0.029045\n",
      "Epoch 056/200 | train 0.024663 | val 0.028374\n",
      "Epoch 057/200 | train 0.024337 | val 0.028088\n",
      "Epoch 058/200 | train 0.024128 | val 0.028081\n",
      "Epoch 059/200 | train 0.023939 | val 0.027231\n",
      "Epoch 060/200 | train 0.024106 | val 0.027818\n",
      "Epoch 061/200 | train 0.023932 | val 0.028071\n",
      "Epoch 062/200 | train 0.023846 | val 0.027912\n",
      "Epoch 063/200 | train 0.023880 | val 0.027222\n",
      "Epoch 064/200 | train 0.023741 | val 0.026434\n",
      "Epoch 065/200 | train 0.023808 | val 0.027299\n",
      "Epoch 066/200 | train 0.023355 | val 0.026835\n",
      "Epoch 067/200 | train 0.023314 | val 0.026585\n",
      "Epoch 068/200 | train 0.022854 | val 0.026842\n",
      "Epoch 069/200 | train 0.022887 | val 0.026570\n",
      "Epoch 070/200 | train 0.022860 | val 0.026394\n",
      "Epoch 071/200 | train 0.022874 | val 0.025950\n",
      "Epoch 072/200 | train 0.022434 | val 0.025281\n",
      "Epoch 073/200 | train 0.022544 | val 0.026521\n",
      "Epoch 074/200 | train 0.022504 | val 0.026663\n",
      "Epoch 075/200 | train 0.022265 | val 0.026128\n",
      "Epoch 076/200 | train 0.022396 | val 0.026233\n",
      "Epoch 077/200 | train 0.021674 | val 0.025910\n",
      "Epoch 078/200 | train 0.021605 | val 0.026640\n",
      "Epoch 079/200 | train 0.021391 | val 0.025436\n",
      "Epoch 080/200 | train 0.021838 | val 0.025241\n",
      "Epoch 081/200 | train 0.021759 | val 0.025961\n",
      "Epoch 082/200 | train 0.021740 | val 0.023924\n",
      "Epoch 083/200 | train 0.021319 | val 0.025762\n",
      "Epoch 084/200 | train 0.020927 | val 0.025772\n",
      "Epoch 085/200 | train 0.021130 | val 0.025832\n",
      "Epoch 086/200 | train 0.021352 | val 0.025591\n",
      "Epoch 087/200 | train 0.020862 | val 0.023966\n",
      "Epoch 088/200 | train 0.020838 | val 0.024470\n",
      "Epoch 089/200 | train 0.020734 | val 0.025401\n",
      "Epoch 090/200 | train 0.020751 | val 0.024529\n",
      "Epoch 091/200 | train 0.020163 | val 0.024435\n",
      "Epoch 092/200 | train 0.020214 | val 0.025758\n",
      "Epoch 093/200 | train 0.019954 | val 0.024963\n",
      "Epoch 094/200 | train 0.019891 | val 0.024329\n",
      "Epoch 095/200 | train 0.019864 | val 0.024461\n",
      "Epoch 096/200 | train 0.019659 | val 0.025062\n",
      "Epoch 097/200 | train 0.019795 | val 0.024107\n",
      "Epoch 098/200 | train 0.019987 | val 0.023814\n",
      "Epoch 099/200 | train 0.019777 | val 0.023248\n",
      "Epoch 100/200 | train 0.019234 | val 0.024540\n",
      "Epoch 101/200 | train 0.018986 | val 0.024562\n",
      "Epoch 102/200 | train 0.019001 | val 0.023849\n",
      "Epoch 103/200 | train 0.019243 | val 0.023091\n",
      "Epoch 104/200 | train 0.018797 | val 0.023614\n",
      "Epoch 105/200 | train 0.018962 | val 0.024324\n",
      "Epoch 106/200 | train 0.018302 | val 0.022766\n",
      "Epoch 107/200 | train 0.018418 | val 0.023661\n",
      "Epoch 108/200 | train 0.018538 | val 0.023217\n",
      "Epoch 109/200 | train 0.018257 | val 0.023085\n",
      "Epoch 110/200 | train 0.018162 | val 0.024292\n",
      "Epoch 111/200 | train 0.018263 | val 0.023741\n",
      "Epoch 112/200 | train 0.017799 | val 0.022555\n",
      "Epoch 113/200 | train 0.017942 | val 0.023307\n",
      "Epoch 114/200 | train 0.017648 | val 0.023137\n",
      "Epoch 115/200 | train 0.017977 | val 0.022106\n",
      "Epoch 116/200 | train 0.017325 | val 0.022089\n",
      "Epoch 117/200 | train 0.017118 | val 0.022394\n",
      "Epoch 118/200 | train 0.017288 | val 0.022681\n",
      "Epoch 119/200 | train 0.017085 | val 0.022341\n",
      "Epoch 120/200 | train 0.016888 | val 0.021372\n",
      "Epoch 121/200 | train 0.016943 | val 0.021953\n",
      "Epoch 122/200 | train 0.016836 | val 0.021698\n",
      "Epoch 123/200 | train 0.016514 | val 0.021531\n",
      "Epoch 124/200 | train 0.016553 | val 0.022972\n",
      "Epoch 125/200 | train 0.016511 | val 0.021953\n",
      "Epoch 126/200 | train 0.016307 | val 0.021036\n",
      "Epoch 127/200 | train 0.016202 | val 0.021564\n",
      "Epoch 128/200 | train 0.015779 | val 0.022315\n",
      "Epoch 129/200 | train 0.015886 | val 0.022243\n",
      "Epoch 130/200 | train 0.015950 | val 0.022146\n",
      "Epoch 131/200 | train 0.016253 | val 0.021901\n",
      "Epoch 132/200 | train 0.016028 | val 0.020922\n",
      "Epoch 133/200 | train 0.015484 | val 0.021128\n",
      "Epoch 134/200 | train 0.015685 | val 0.020415\n",
      "Epoch 135/200 | train 0.015425 | val 0.023660\n",
      "Epoch 136/200 | train 0.015218 | val 0.021086\n",
      "Epoch 137/200 | train 0.015334 | val 0.021450\n",
      "Epoch 138/200 | train 0.015254 | val 0.021142\n",
      "Epoch 139/200 | train 0.015138 | val 0.022266\n",
      "Epoch 140/200 | train 0.014617 | val 0.020582\n",
      "Epoch 141/200 | train 0.014850 | val 0.020816\n",
      "Epoch 142/200 | train 0.014677 | val 0.020718\n",
      "Epoch 143/200 | train 0.014615 | val 0.021912\n",
      "Epoch 144/200 | train 0.014522 | val 0.020539\n",
      "Epoch 145/200 | train 0.014534 | val 0.021927\n",
      "Epoch 146/200 | train 0.014460 | val 0.020504\n",
      "Epoch 147/200 | train 0.014204 | val 0.019725\n",
      "Epoch 148/200 | train 0.014131 | val 0.020463\n",
      "Epoch 149/200 | train 0.014022 | val 0.020773\n",
      "Epoch 150/200 | train 0.013801 | val 0.019962\n",
      "Epoch 151/200 | train 0.013804 | val 0.020841\n",
      "Epoch 152/200 | train 0.013584 | val 0.020065\n",
      "Epoch 153/200 | train 0.013497 | val 0.020607\n",
      "Epoch 154/200 | train 0.013700 | val 0.022214\n",
      "Epoch 155/200 | train 0.013517 | val 0.020020\n",
      "Epoch 156/200 | train 0.013392 | val 0.021025\n",
      "Epoch 157/200 | train 0.013040 | val 0.020588\n",
      "Epoch 158/200 | train 0.013214 | val 0.020334\n",
      "Epoch 159/200 | train 0.013192 | val 0.020164\n",
      "Epoch 160/200 | train 0.013097 | val 0.020603\n",
      "Epoch 161/200 | train 0.012932 | val 0.020689\n",
      "Epoch 162/200 | train 0.013042 | val 0.019826\n",
      "Epoch 163/200 | train 0.012981 | val 0.019776\n",
      "Epoch 164/200 | train 0.012949 | val 0.019737\n",
      "Epoch 165/200 | train 0.012697 | val 0.020683\n",
      "Epoch 166/200 | train 0.012641 | val 0.020265\n",
      "Epoch 167/200 | train 0.012747 | val 0.020060\n",
      "Epoch 168/200 | train 0.012330 | val 0.021267\n",
      "Epoch 169/200 | train 0.012453 | val 0.019693\n",
      "Epoch 170/200 | train 0.012537 | val 0.021045\n",
      "Epoch 171/200 | train 0.012386 | val 0.020440\n",
      "Epoch 172/200 | train 0.012640 | val 0.020741\n",
      "Epoch 173/200 | train 0.012517 | val 0.020137\n",
      "Epoch 174/200 | train 0.012065 | val 0.020034\n",
      "Epoch 175/200 | train 0.011894 | val 0.019897\n",
      "Epoch 176/200 | train 0.012361 | val 0.020591\n",
      "Epoch 177/200 | train 0.011869 | val 0.020154\n",
      "Epoch 178/200 | train 0.011914 | val 0.020331\n",
      "Epoch 179/200 | train 0.012145 | val 0.021001\n",
      "Epoch 180/200 | train 0.012016 | val 0.021098\n",
      "Epoch 181/200 | train 0.012228 | val 0.020383\n",
      "Epoch 182/200 | train 0.011988 | val 0.020200\n",
      "Epoch 183/200 | train 0.011938 | val 0.019333\n",
      "Epoch 184/200 | train 0.012053 | val 0.020655\n",
      "Epoch 185/200 | train 0.011839 | val 0.019825\n",
      "Epoch 186/200 | train 0.011796 | val 0.020994\n",
      "Epoch 187/200 | train 0.011623 | val 0.020132\n",
      "Epoch 188/200 | train 0.011721 | val 0.021369\n",
      "Epoch 189/200 | train 0.011869 | val 0.020241\n",
      "Epoch 190/200 | train 0.011685 | val 0.019777\n",
      "Epoch 191/200 | train 0.011672 | val 0.020065\n",
      "Epoch 192/200 | train 0.011898 | val 0.020842\n",
      "Epoch 193/200 | train 0.011874 | val 0.021061\n",
      "Epoch 194/200 | train 0.011676 | val 0.020669\n",
      "Epoch 195/200 | train 0.011481 | val 0.020137\n",
      "Epoch 196/200 | train 0.011878 | val 0.021365\n",
      "Epoch 197/200 | train 0.011789 | val 0.021561\n",
      "Epoch 198/200 | train 0.011685 | val 0.018994\n",
      "Epoch 199/200 | train 0.011955 | val 0.020654\n",
      "Epoch 200/200 | train 0.011663 | val 0.020572\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def save_final_models(noise_pred_net, out_dir):\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"noise_pred_net\": noise_pred_net.state_dict(),\n",
    "        },\n",
    "        out_dir / \"model_final.pth\",\n",
    "    )\n",
    "    print(f\"Saved to {out_dir / 'models.pth'}\")\n",
    "\n",
    "\n",
    "save_final_models(noise_prediction_net,\n",
    "                  \"../models/robot_transformer_v7_91_tool_hand_state\")"
   ],
   "id": "876a679f04bc3349",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-17T01:28:24.853632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import robomimic\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "from robomimic.utils.vis_utils import depth_to_rgb\n",
    "from robomimic.envs.env_base import EnvBase, EnvType\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "env_meta = FileUtils.get_env_metadata_from_dataset(dataset_path=data_path)\n",
    "\n",
    "dummy_spec = dict(\n",
    "    obs=dict(\n",
    "        low_dim=[\"robot0_eef_pos\"],\n",
    "        rgb=[\"agentview_image\"]\n",
    "        # rgb=[\"robot0_eye_in_hand_image\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "ObsUtils.initialize_obs_utils_with_obs_specs(obs_modality_specs=dummy_spec)\n",
    "\n",
    "env = EnvUtils.create_env_from_metadata(env_meta=env_meta, render=True, render_offscreen=True, use_image_obs=True)\n",
    "\n",
    "a = env.reset()\n",
    "\n",
    "from collections import deque\n",
    "obs_deque  = deque(maxlen=obs_horizon)\n",
    "act_deque  = deque(maxlen=obs_horizon)\n",
    "rewards    = []\n",
    "imgs       = []\n",
    "step_idx   = 0\n",
    "\n",
    "max_steps = 1000\n",
    "action_horizon  = 2\n",
    "\n",
    "# ─── 6. Main rollout ──────────────────────────────────────────────────────────\n",
    "obs = env.reset()\n",
    "state_vec = env.get_state()[\"states\"]\n",
    "# wrap obs in same format as env.step\n",
    "for i in range(obs_deque.maxlen):\n",
    "    obs_deque.append(state_vec)\n",
    "    act_deque.append(np.zeros(action_dim, dtype=np.float32))\n",
    "\n",
    "pbar = tqdm(total=max_steps)\n",
    "done = False\n",
    "\n",
    "while not done and step_idx < max_steps:\n",
    "    # 6.1 build the image & action history tensor\n",
    "    state_np = np.array([obs_deque[i] for i in range(obs_deque.maxlen)])\n",
    "\n",
    "    actions_hist = torch.stack(\n",
    "        [torch.from_numpy(a) for a in list(act_deque)],\n",
    "        dim=0\n",
    "    ).to(device)                           # (1, H_a, 7)\n",
    "\n",
    "    # 6.2 compute visual features + conditioning\n",
    "    with torch.no_grad():\n",
    "        state_feat = torch.Tensor(state_np).to(device)                # (1, C)\n",
    "        # obs_features = torch.cat([state_feat, actions_hist], dim=-1)\n",
    "        obs_features = state_feat\n",
    "        obs_cond = obs_features.flatten(start_dim=0).unsqueeze(0)\n",
    "\n",
    "        # 6.3 sample a future action sequence via diffusion\n",
    "        B = 1\n",
    "        pred_actions = torch.randn((B, pred_horizon, action_dim), device=device)\n",
    "        noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "        for t in noise_scheduler.timesteps:\n",
    "            noise_pred    = noise_prediction_net(pred_actions, t, global_cond=obs_cond)\n",
    "            out           = noise_scheduler.step(noise_pred, t, pred_actions)\n",
    "            pred_actions  = out.prev_sample\n",
    "\n",
    "    pred_actions = pred_actions.cpu().numpy()[0]        # (pred_horizon, 7)\n",
    "\n",
    "    # 6.4 execute the next block of actions\n",
    "    start = obs_horizon\n",
    "    end   = start + action_horizon\n",
    "    action_block = pred_actions[start:end]          # (5, 7)\n",
    "\n",
    "    for act in action_block:\n",
    "        obs, rew, done, info = env.step(act)\n",
    "        obs = obs if isinstance(obs, dict) else obs[0]\n",
    "\n",
    "        state = env.get_state()[\"states\"]\n",
    "\n",
    "        frame = env.render(mode=\"rgb_array\", height=512, width=512)\n",
    "\n",
    "        obs_deque.append(state)\n",
    "        act_deque.append(act.astype(np.float32))\n",
    "\n",
    "        rewards.append(rew)\n",
    "        imgs.append(frame)\n",
    "\n",
    "        step_idx += 1\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix(reward=float(rew))\n",
    "\n",
    "        if done or step_idx >= max_steps:\n",
    "            break\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "print(f\"Rollout finished: {step_idx} steps, total reward {sum(rewards):.2f}\")"
   ],
   "id": "7a1cf4859475c526",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_eef_pos']\n",
      "using obs modality: rgb with keys: ['agentview_image']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Probing, EGL cannot run on this device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created environment with name ToolHang\n",
      "Action size is 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 40/1000 [00:11<04:20,  3.69it/s, reward=0]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T01:27:46.714275Z",
     "start_time": "2025-06-17T01:27:43.131571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import imageio\n",
    "\n",
    "video_path = \"test_state.mp4\"\n",
    "fps = 24f\n",
    "\n",
    "with imageio.get_writer(video_path, fps=fps, codec=\"libx264\") as writer:\n",
    "    for frame in imgs:\n",
    "        writer.append_data(frame)\n",
    "\n",
    "print(f\"Saved video to {video_path}\")"
   ],
   "id": "bcf3810ce87809f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video to test_state.mp4\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "95703de4232c80ab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
